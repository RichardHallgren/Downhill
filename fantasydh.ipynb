{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fantasy downhill\n",
    "The goal of this model is to create a fantasy downhill team based on the riders expected results and the cost of the riders. It will choose the riders with the best expected points return and keeping the teams budget of 1 500 000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter venue and date to predict here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = pd.read_csv('Points.csv', sep=';')\n",
    "points_dict = dict(zip(points_df.Rank, points_df.Points))\n",
    "\n",
    "#ENTER VENUE AND DATE HERE\n",
    "    \n",
    "ven_pred = 'Lousa'\n",
    "date_pred = '20200322'\n",
    "\n",
    "#ENTER RIDERS NOT PARTICIPATING IN RACE HERE\n",
    "np_riders = ['Martin MAES']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes of riders whos results should be predicted\n",
    "\n",
    "Some riders are not participating in all races, this could be because of injuries, or they are riders that won't participate in all world cups for various reasons (for example Martin Maes is an enduro rider who only sometimes (rarely) participate in downhill events, therefore he's removed from the participating riders). The create_prediction_df creates dataframes containing only the riders that should be included in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_df():\n",
    "\n",
    "    \n",
    "    comp_df = pd.read_csv('riderprices2020.csv', sep=';')\n",
    "    comp_df_m = comp_df[(comp_df.Gender == 'M') & (comp_df.Injured == 'No') & (~comp_df.Name.isin(np_riders))].copy()\n",
    "    comp_df_w = comp_df[(comp_df.Gender == 'W') & (comp_df.Injured == 'No')].copy()\n",
    "\n",
    "    comp_dfs = [comp_df_m, comp_df_w]  \n",
    "    \n",
    "    for df in comp_dfs:\n",
    "        \n",
    "        df.drop(['Price', 'Injured', 'Gender'], axis=1, inplace=True)\n",
    "        df['Venue'] = ven_pred\n",
    "        df['Date'] = pd.to_datetime(date_pred, format='%Y%m%d')\n",
    "        df['Year'] = df.Date.dt.year\n",
    "\n",
    "    return (comp_df_m, comp_df_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes\n",
    "\n",
    "The function create_results_from_UCI_df creates a dataframe from excel-files containing results downloaded from the UCI (Union Cycliste Internationale) Website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_from_UCI_df(path):\n",
    "\n",
    "    files = os.listdir(path)\n",
    "    files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "    filepaths = [path + '/' + file for file in files_xlsx]\n",
    "\n",
    "    udf = pd.DataFrame()\n",
    "    for f in filepaths:\n",
    "        data = pd.read_excel(f)\n",
    "        stripped_f = f.rstrip('.xlsx').replace('Results_UCI_M/', '').replace('Results_UCI_W/', '')\n",
    "        split_f = stripped_f.split('_')\n",
    "        data['Venue'] = split_f[0]\n",
    "        data['Category'] = split_f[1]\n",
    "        data['Date'] = split_f[2]\n",
    "        data['Name'] = data['First Name'] + ' ' + data['Last Name']\n",
    "        data['Date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
    "        data.drop(['First Name', 'Last Name', 'Phase', 'Heat', 'IRM', 'Team', 'Gender', 'Result', 'Country', 'Category', 'BIB'], axis=1, inplace=True)\n",
    "        udf = udf.append(data, sort=False)\n",
    "        udf.dropna(subset=['Rank'], inplace=True)\n",
    "        udf.Rank = udf.Rank.astype(int)\n",
    "        udf = udf[(udf.Rank < 81)]\n",
    "        udf.sort_values(by=['Date', 'Rank'], inplace=True)\n",
    " \n",
    "        #Create points feature\n",
    "        udf['Points'] = udf.Rank.map(points_dict)\n",
    "        udf.Points.fillna(0, inplace=True)\n",
    "    \n",
    "        #Create year feature\n",
    "        udf['Year'] = udf.Date.dt.year\n",
    "    \n",
    "    return udf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function create_results_from_scraped_web_data creates a dataframe from the results scraped from a separate downhill website (see the separate Scraped_web_data_ETL.ipynb for more info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_from_scraped_web_data():\n",
    "    scraped_df = pd.read_excel('race_dfs_output.xlsx')\n",
    "    \n",
    "    #change name errors\n",
    "    name_dict = {'Sam HILL' : 'Samuel HILL', 'Mick HANNAH' : 'Michael HANNAH'}\n",
    "    venue_dict = {'Fort-William' : 'Fortwilliam', 'Les-Gets' : 'Lesgets', 'Les-Deux-Alpes' : 'Lesdeuxalpes'}\n",
    "    scraped_df.Name.replace(name_dict, inplace=True)\n",
    "    scraped_df.Venue.replace(venue_dict, inplace=True)\n",
    "    scraped_df['Date'] = pd.to_datetime(scraped_df['Date'], format='%Y%m%d')\n",
    "    \n",
    "    #Create points feature\n",
    "    scraped_df['Points'] = scraped_df.Rank.map(points_dict)\n",
    "    scraped_df.Points.fillna(0, inplace=True)\n",
    "    scraped_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    scraped_df = scraped_df[(scraped_df.Rank < 81)]\n",
    "\n",
    "\n",
    "    scraped_df.sort_values(by=['Date', 'Rank'], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    return scraped_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features\n",
    "The create_features and findpreviouswin functions creates 5 features based on earlier results the rider has had. These features are chosen because of the assumption that prior results from the rider will be an indicator of future results. Especially more recent results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(cfdf):\n",
    "    #Create Moving Average over last 3 races\n",
    "    cfdf['MA3 Pos'] = cfdf.groupby('Name')['Rank'].transform(lambda x: x.rolling(3, 1).mean().shift())\n",
    "\n",
    "    #Create last race position feature\n",
    "    cfdf['Last RP'] = cfdf.groupby('Name')['Rank'].transform(lambda x: x.rolling(1, 1).mean().shift())\n",
    "\n",
    "    #Best position in the last 5 races\n",
    "    cfdf['Best pos'] = cfdf.groupby('Name')['Rank'].transform(lambda x: x.rolling(5, 1).min().shift())\n",
    "\n",
    "    #Average position current season\n",
    "    cfdf['AP this year'] = cfdf.groupby(['Name', 'Year'])['Rank'].transform(lambda x: x.rolling(10, 1).mean().shift())\n",
    "\n",
    "    #Number of races rider has participated in current season\n",
    "    #cfdf['Races CS'] = cfdf.groupby(['Name', 'Year'])['Rank'].transform(lambda x: x.rolling(10, 1).count().shift())\n",
    "    #cfdf['Races CS'].fillna(0, inplace=True)\n",
    "    \n",
    "    return cfdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpreviouswin(compdate, compyear, name, df):  \n",
    "    # Function to create a feature for the riders average position the previous year\n",
    "    \n",
    "    avgpos_pyear = df[(df.Name == name) & (df.Year == compyear-1)].Rank.mean()\n",
    "    \n",
    "    return pd.Series({'AP last season' : avgpos_pyear})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fantasy model\n",
    "\n",
    "To avoid data leakage the last race will be hold out from the training data instead of holding out random samples from the training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fantasy_model(dfinp):\n",
    "    \n",
    "    # Set dev_model to 1 to test the model before training on entire dataset. \n",
    "    # dev_model = 0 means that the model will take all data into account before predicting the\n",
    "    # upcoming race\n",
    "    dev_model = 0\n",
    "    \n",
    "    #preprocessing of dataframe\n",
    "    \n",
    "    #train and test set to evaluate performance of model before training model on all data and using it to predict\n",
    "    #future competitions\n",
    "    \n",
    "    if dev_model == 1:\n",
    "    \n",
    "        df_test = dfinp[(dfinp['Venue'] == 'Snowshoe') & (dfinp['Date'] == '2019-09-06')].copy()\n",
    "        df_train = dfinp[(dfinp['Venue'] != 'Snowshoe') & (dfinp['Date'] != '2019-09-06') & (dfinp.Rank < 81)].copy()\n",
    "    \n",
    "    #create df to train model on all data before using it to predict upcoming competitions, excluding upcoming competition\n",
    "    \n",
    "    elif dev_model == 0:\n",
    "    \n",
    "        df_train = dfinp[(dfinp['Venue'] != ven_pred) & (dfinp['Date'] != date_pred) & (dfinp.Rank < 81)].copy()\n",
    "        #df_pred is the dataframe containing the venue to be predicted\n",
    "        df_test = dfinp[(dfinp['Venue'] == ven_pred) & (dfinp['Date'] == pd.to_datetime(date_pred, format='%Y%m%d'))].copy()\n",
    "\n",
    "\n",
    "    \n",
    "    y_train = df_train.Points\n",
    "    df_train.drop('Points', axis=1, inplace=True)\n",
    "    y_test = df_test.Points\n",
    "    df_test.drop('Points', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Choose features, Name could be a leaky feature during training, but it doesn't seem to affect the\n",
    "    # results negatively during evaluation.\n",
    "    numerical_cols = ['Age', 'Year', 'MA3 Pos', 'Last RP', 'Best pos', 'AP this year', 'AP last season']\n",
    "    categorical_cols = ['Venue', 'Name']\n",
    "    \n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "     ])\n",
    "    \n",
    "    \n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical_cols + numerical_cols\n",
    "    X_train = df_train[my_cols].copy()\n",
    "    #X_test = df_pred[my_cols].copy()\n",
    "    X_test = df_test[my_cols].copy()\n",
    "    \n",
    "    n_jobs = 4\n",
    "    max_depth = 6\n",
    "    alpha = 0.001\n",
    "    no_of_trees = 1800\n",
    "    \n",
    "    if dev_model == 1:\n",
    "        \n",
    "        eval_set = [(df_test, y_test)]\n",
    "            \n",
    "        model = XGBRegressor(n_estimators=no_of_trees, learning_rate=alpha, n_jobs=n_jobs, max_depth=max_depth, \n",
    "                             objective=\"reg:squarederror\", eval_set = eval_set\n",
    "                            ,early_stopping_rounds=100, eval_metric='mae')\n",
    "    \n",
    "    elif dev_model == 0:\n",
    "        model = XGBRegressor(n_estimators=no_of_trees, learning_rate=alpha, n_jobs=n_jobs, max_depth=max_depth, \n",
    "                             objective=\"reg:squarederror\")\n",
    "        \n",
    "    \n",
    "    # Create a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "    \n",
    "    # Preprocessing of training data, fit model \n",
    "    my_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict points distribution for the race event\n",
    "    test_pred = my_pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    if dev_model == 1:\n",
    "        mae = mean_absolute_error(y_test, test_pred)\n",
    "        r2score = r2_score(y_test, test_pred) # fraction of variance explained by the model\n",
    "    \n",
    "        print('MAE:', mae)\n",
    "        print('R^2 Score:', r2score)\n",
    "    \n",
    "    return pd.Series(test_pred, df_test.Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def race_prediction_men():\n",
    "    #enter names of result folders\n",
    "    path1 = 'Results_UCI_M'\n",
    "    rdf1 = create_results_from_UCI_df(path1)\n",
    "    \n",
    "    scraped_df = create_results_from_scraped_web_data()\n",
    "\n",
    "    result_df_M = scraped_df.append(rdf1, sort=True)\n",
    "        \n",
    "\n",
    "    comp_df_m = create_prediction_df()[0]\n",
    "    \n",
    "    result_df_M = result_df_M.append(comp_df_m, sort=True)\n",
    "\n",
    "    \n",
    "    #create dataframe with features\n",
    "    mdf = create_features(result_df_M)\n",
    "\n",
    "    #create feature with average number points per race for the previous season\n",
    "    mdf[['AP last season']] = mdf.apply(lambda row: findpreviouswin(row.Date, row.Year, row.Name, mdf), axis=1)\n",
    "\n",
    "    mdf.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    #Create correlation plot over the dataframe with numerical features\n",
    "    #f, ax = plt.subplots(figsize=(10, 8))\n",
    "    #corr = mdf.corr()\n",
    "    #sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "    #        square=True, ax=ax)\n",
    "    \n",
    "    return fantasy_model(mdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Amaury PIERRON       72.175255\n",
       "Loic BRUNI           72.508911\n",
       "Troy BROSNAN         94.453789\n",
       "Danny HART           83.782768\n",
       "Loris VERGIER        64.453842\n",
       "                       ...    \n",
       "Kaos SEAGRAVE        11.832509\n",
       "Francisco PARDAL     11.733274\n",
       "Noel NIEDERBERGER    18.819372\n",
       "Gaëtan RUFFIN        12.003074\n",
       "Rupert CHAPMAN       13.241374\n",
       "Length: 87, dtype: float32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_prediction_men()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_prediction_women():\n",
    "    #enter names of result folders\n",
    "    path1 = 'Results_UCI_W'\n",
    "    rdf1 = create_results_from_UCI_df(path1)\n",
    "    #path2 = 'Results_Web_M'\n",
    "    #rdf2 = create_results_from_web_df(path2)\n",
    "    #result_df_M = rdf2.append(rdf1, sort=True)\n",
    "\n",
    "    \n",
    "    comp_df_w = create_prediction_df()[1]\n",
    "\n",
    "    result_df_W = rdf1.append(comp_df_w, sort=True)\n",
    "\n",
    "\n",
    "\n",
    "    #create dataframe with features\n",
    "    wdf = create_features(result_df_W)\n",
    "\n",
    "    #create feature with average number points per race for the previous season\n",
    "    wdf[['AP last season']] = wdf.apply(lambda row: findpreviouswin(row.Date, row.Year, row.Name, wdf), axis=1)\n",
    "\n",
    "    \n",
    "    return fantasy_model(wdf)\n",
    "#race_prediction_women()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rider selection\n",
    "All riders have a set price (this price does not update during the season). The function rider_selection reads in a dataframe containing the prices and the predictions for the races. It uses these dataframes to calculate how much points per dollar each rider is expected to return. This function will be used when finding the best possible rider combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rider_selection(gender):\n",
    "    rider_price_df = pd.read_csv('riderprices2020.csv', sep=';')\n",
    "    \n",
    "    \n",
    "    if gender == 'M':\n",
    "        predictions = race_prediction_men()\n",
    "    else:\n",
    "        predictions = race_prediction_women()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    pri_df = pd.DataFrame(predictions).reset_index()\n",
    "    pri_df = pri_df.rename(columns={0: \"Points\"})\n",
    "\n",
    "    pri_df = pri_df.merge(rider_price_df, left_on='Name', right_on='Name', how='left')\n",
    "    pri_df['Pts./k$'] = pri_df.Points / pri_df.Price*1000\n",
    "    #print(pri_df.head(50))\n",
    "    \n",
    "    if gender == 'M':\n",
    "        pri_df = pri_df.groupby('Price').nth(list(range(4))).reset_index()\n",
    "    else:\n",
    "        pri_df = pri_df.groupby('Price').nth(list(range(2))).reset_index()\n",
    "    \n",
    "    \n",
    "    return pri_df[(pri_df['Pts./k$'] > 0.1)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best possible combination of riders\n",
    "The goal is to have the best possible fantasy downhill team, consisting of a maximum of 6 riders. Maximum 2 women riders and maximum 4 male riders.\n",
    "\n",
    "This function, find_rider_combinations, iterates through all the combinations of 4 Male riders and 2 Female riders and fins the combination that has the highest expected total number of points within the team budget of 1 500 000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rider_combinations():\n",
    "    import itertools    \n",
    "    from itertools import combinations\n",
    "    \n",
    "    #dataframe with riders in the men category\n",
    "    ridercm_df = rider_selection('M')\n",
    "    \n",
    "    #dataframe with riders in the women category\n",
    "    ridercw_df = rider_selection('W')\n",
    "    #Create all possible combinations of riders\n",
    "    #mask for non participating riders\n",
    "    #nonpart = (riderc_df.Name != \"Martin MAES\")\n",
    "    #rcomb_df = pd.DataFrame.from_records(list(itertools.combinations(riderc_df[nonpart].Name, 4)), columns=['R1', 'R2', 'R3', 'R4'])\n",
    "    \n",
    "    \n",
    "    #Create two separate dataframes for men and women. \n",
    "    #Create combinations of 4 male riders and combinations of 2 female riders.\n",
    "    \n",
    "    rcombm_df = pd.DataFrame.from_records(list(itertools.combinations(ridercm_df.Name, 4)), columns=['MR1', 'MR2', 'MR3', 'MR4'])\n",
    "\n",
    "    #Dictionaries of rider & price/points\n",
    "    rpdict = dict(zip(ridercm_df.Name,ridercm_df.Price))\n",
    "    rptdict = dict(zip(ridercm_df.Name,ridercm_df.Points))\n",
    "\n",
    "    rcombm_df['CPriceM'] = rcombm_df.MR1.map(rpdict) + rcombm_df.MR2.map(rpdict) + rcombm_df.MR3.map(rpdict) + rcombm_df.MR4.map(rpdict)\n",
    "    rcombm_df['CPointsM'] = rcombm_df.MR1.map(rptdict) + rcombm_df.MR2.map(rptdict) + rcombm_df.MR3.map(rptdict) + rcombm_df.MR4.map(rptdict)\n",
    "    rcombm_df['Comb. Pts/k$'] = rcombm_df.CPointsM / rcombm_df.CPriceM * 1000\n",
    "\n",
    "    rcombm_df.sort_values(by=['CPointsM'], ascending = False, inplace=True)\n",
    "    rcombm_df['RidersM'] = list(zip(rcombm_df.MR1, rcombm_df.MR2, rcombm_df.MR3, rcombm_df.MR4))\n",
    "\n",
    "    #rcombm_df.drop(rcombm_df[rcombm_df.CPriceM > 50000].index, inplace=True)\n",
    "\n",
    "    rcombm_df = rcombm_df[(rcombm_df.CPriceM < 1500000) & (rcombm_df.CPriceM > 340000)].copy()\n",
    "    \n",
    "    #Creation of dataframes for female riders\n",
    "    rcombw_df = pd.DataFrame.from_records(list(itertools.combinations(ridercw_df.Name, 2)), columns=['WR1', 'WR2'])\n",
    "    \n",
    "    rpwdict = dict(zip(ridercw_df.Name,ridercw_df.Price))\n",
    "    rptwdict = dict(zip(ridercw_df.Name,ridercw_df.Points))\n",
    "    \n",
    "    rcombw_df['CPriceW'] = rcombw_df.WR1.map(rpwdict) + rcombw_df.WR2.map(rpwdict) \n",
    "    rcombw_df['CPointsW'] = rcombw_df.WR1.map(rptwdict) + rcombw_df.WR2.map(rptwdict) \n",
    "    rcombw_df['Comb. Pts/k$ W'] = rcombw_df.CPointsW / rcombw_df.CPriceW * 1000\n",
    "\n",
    "    rcombw_df.sort_values(by=['CPointsW'], ascending = False, inplace=True)\n",
    "    rcombw_df['RidersW'] = list(zip(rcombw_df.WR1, rcombw_df.WR2))\n",
    "\n",
    "    #find best combinations of both men and women\n",
    "    combinate_df = pd.DataFrame.from_records(list(itertools.product(rcombw_df.RidersW, rcombm_df.RidersM)), columns=['RidersW', 'RidersM'])\n",
    "    \n",
    "    \n",
    "    combinate_df = combinate_df.merge(rcombw_df, left_on='RidersW', right_on='RidersW')\n",
    "    combinate_df = combinate_df.merge(rcombm_df, left_on='RidersM', right_on='RidersM')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    combinate_df['Combined Price'] = combinate_df.CPriceW + combinate_df.CPriceM\n",
    "    combinate_df['Combined Points'] = combinate_df.CPointsW + combinate_df.CPointsM\n",
    "\n",
    "    combinate_df.drop(['MR1', 'MR2', 'MR3', 'MR4', 'WR1', 'WR2', 'CPriceW', 'CPriceM', 'CPointsW', 'CPointsM'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    combinate_df.sort_values(by=['Combined Points'], ascending = False, inplace=True)\n",
    "    \n",
    "    return combinate_df[(combinate_df['Combined Price'] < 1500001)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RidersW</th>\n",
       "      <th>RidersM</th>\n",
       "      <th>Comb. Pts/k$ W</th>\n",
       "      <th>Comb. Pts/k$</th>\n",
       "      <th>Combined Price</th>\n",
       "      <th>Combined Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>384930</td>\n",
       "      <td>(Agnes DELEST, Myriam NICOLE)</td>\n",
       "      <td>(Joshua BARTH, Brendan FAIRCLOUGH, Greg MINNAAR, Troy BROSNAN)</td>\n",
       "      <td>0.427805</td>\n",
       "      <td>0.238579</td>\n",
       "      <td>1495000</td>\n",
       "      <td>443.719961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424230</td>\n",
       "      <td>(Agnes DELEST, Myriam NICOLE)</td>\n",
       "      <td>(Noel NIEDERBERGER, Brendan FAIRCLOUGH, Greg MINNAAR, Troy BROSNAN)</td>\n",
       "      <td>0.427805</td>\n",
       "      <td>0.237414</td>\n",
       "      <td>1495000</td>\n",
       "      <td>442.514387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1023618</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Joshua BARTH, Brendan FAIRCLOUGH, Laurie GREENLAND, Greg MINNAAR)</td>\n",
       "      <td>0.398145</td>\n",
       "      <td>0.242604</td>\n",
       "      <td>1485000</td>\n",
       "      <td>441.925718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1104018</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Noel NIEDERBERGER, Brendan FAIRCLOUGH, Laurie GREENLAND, Greg MINNAAR)</td>\n",
       "      <td>0.398145</td>\n",
       "      <td>0.241348</td>\n",
       "      <td>1485000</td>\n",
       "      <td>440.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200918</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Brendan FAIRCLOUGH, David TRUMMER, Charlie HARRISON, Greg MINNAAR)</td>\n",
       "      <td>0.398145</td>\n",
       "      <td>0.248976</td>\n",
       "      <td>1450000</td>\n",
       "      <td>439.329014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62963988</td>\n",
       "      <td>(Melanie CHAPPAZ, Cecile RAVANEL)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.126059</td>\n",
       "      <td>725000</td>\n",
       "      <td>138.816641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62963987</td>\n",
       "      <td>(Janine HUBSCHER, Melanie CHAPPAZ)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)</td>\n",
       "      <td>1.525740</td>\n",
       "      <td>0.126059</td>\n",
       "      <td>435000</td>\n",
       "      <td>138.816641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62963986</td>\n",
       "      <td>(Vali HÖLL, Nina HOFFMAN)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)</td>\n",
       "      <td>0.130778</td>\n",
       "      <td>0.126059</td>\n",
       "      <td>1075000</td>\n",
       "      <td>138.816641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62963985</td>\n",
       "      <td>(Melanie CHAPPAZ, Mille JOHNSET)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)</td>\n",
       "      <td>0.457722</td>\n",
       "      <td>0.126059</td>\n",
       "      <td>575000</td>\n",
       "      <td>138.816641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62963999</td>\n",
       "      <td>(Cecile RAVANEL, Nina HOFFMAN)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)</td>\n",
       "      <td>0.135621</td>\n",
       "      <td>0.126059</td>\n",
       "      <td>1050000</td>\n",
       "      <td>138.816641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49052258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     RidersW  \\\n",
       "384930    (Agnes DELEST, Myriam NICOLE)        \n",
       "424230    (Agnes DELEST, Myriam NICOLE)        \n",
       "1023618   (Morgane CHARRE, Myriam NICOLE)      \n",
       "1104018   (Morgane CHARRE, Myriam NICOLE)      \n",
       "1200918   (Morgane CHARRE, Myriam NICOLE)      \n",
       "...                                   ...      \n",
       "62963988  (Melanie CHAPPAZ, Cecile RAVANEL)    \n",
       "62963987  (Janine HUBSCHER, Melanie CHAPPAZ)   \n",
       "62963986  (Vali HÖLL, Nina HOFFMAN)            \n",
       "62963985  (Melanie CHAPPAZ, Mille JOHNSET)     \n",
       "62963999  (Cecile RAVANEL, Nina HOFFMAN)       \n",
       "\n",
       "                                                                          RidersM  \\\n",
       "384930    (Joshua BARTH, Brendan FAIRCLOUGH, Greg MINNAAR, Troy BROSNAN)            \n",
       "424230    (Noel NIEDERBERGER, Brendan FAIRCLOUGH, Greg MINNAAR, Troy BROSNAN)       \n",
       "1023618   (Joshua BARTH, Brendan FAIRCLOUGH, Laurie GREENLAND, Greg MINNAAR)        \n",
       "1104018   (Noel NIEDERBERGER, Brendan FAIRCLOUGH, Laurie GREENLAND, Greg MINNAAR)   \n",
       "1200918   (Brendan FAIRCLOUGH, David TRUMMER, Charlie HARRISON, Greg MINNAAR)       \n",
       "...                                                                       ...       \n",
       "62963988  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)        \n",
       "62963987  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)        \n",
       "62963986  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)        \n",
       "62963985  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)        \n",
       "62963999  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRUZ, George BRANNIGAN)        \n",
       "\n",
       "          Comb. Pts/k$ W  Comb. Pts/k$  Combined Price  Combined Points  \n",
       "384930    0.427805        0.238579      1495000         443.719961       \n",
       "424230    0.427805        0.237414      1495000         442.514387       \n",
       "1023618   0.398145        0.242604      1485000         441.925718       \n",
       "1104018   0.398145        0.241348      1485000         440.720144       \n",
       "1200918   0.398145        0.248976      1450000         439.329014       \n",
       "...            ...             ...          ...                ...       \n",
       "62963988  0.261555        0.126059      725000          138.816641       \n",
       "62963987  1.525740        0.126059      435000          138.816641       \n",
       "62963986  0.130778        0.126059      1075000         138.816641       \n",
       "62963985  0.457722        0.126059      575000          138.816641       \n",
       "62963999  0.135621        0.126059      1050000         138.816641       \n",
       "\n",
       "[49052258 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the entire column width\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Find the optimal rider combinations\n",
    "find_rider_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

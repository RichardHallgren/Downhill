{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = pd.read_csv('Points.csv', sep=';')\n",
    "points_dict = dict(zip(points_df.Rank, points_df.Points))\n",
    "\n",
    "#ENTER VENUE AND DATE HERE\n",
    "    \n",
    "ven_pred = 'Lousa'\n",
    "date_pred = '20200322'\n",
    "\n",
    "#ENTER RIDERS NOT PARTICIPATING IN RACE HERE\n",
    "np_riders = ['Martin MAES']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_df():\n",
    "\n",
    "    \n",
    "    comp_df = pd.read_csv('riderprices2020.csv', sep=';')\n",
    "    comp_df_m = comp_df[(comp_df.Gender == 'M') & (comp_df.Injured == 'No') & (~comp_df.Name.isin(np_riders))].copy()\n",
    "    comp_df_w = comp_df[(comp_df.Gender == 'W') & (comp_df.Injured == 'No')].copy()\n",
    "\n",
    "    comp_dfs = [comp_df_m, comp_df_w]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for df in comp_dfs:\n",
    "        \n",
    "        df.drop(['Price', 'Injured', 'Gender'], axis=1, inplace=True)\n",
    "        df['Venue'] = ven_pred\n",
    "        df['Date'] = pd.to_datetime(date_pred, format='%Y%m%d')\n",
    "        df['Year'] = df.Date.dt.year\n",
    "\n",
    "    return (comp_df_m, comp_df_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_from_UCI_df(path):\n",
    "\n",
    "    files = os.listdir(path)\n",
    "    files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "    filepaths = [path + '/' + file for file in files_xlsx]\n",
    "\n",
    "    udf = pd.DataFrame()\n",
    "    for f in filepaths:\n",
    "        data = pd.read_excel(f)\n",
    "        stripped_f = f.rstrip('.xlsx').replace('Results_UCI_M/', '').replace('Results_UCI_W/', '')\n",
    "        split_f = stripped_f.split('_')\n",
    "        data['Venue'] = split_f[0]\n",
    "        data['Category'] = split_f[1]\n",
    "        data['Date'] = split_f[2]\n",
    "        data['Name'] = data['First Name'] + ' ' + data['Last Name']\n",
    "        data['Date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
    "        data.drop(['First Name', 'Last Name', 'Phase', 'Heat', 'IRM', 'Team', 'Gender', 'Result', 'Country', 'Category', 'BIB'], axis=1, inplace=True)\n",
    "        udf = udf.append(data, sort=False)\n",
    "        udf.dropna(subset=['Rank'], inplace=True)\n",
    "        udf.Rank = udf.Rank.astype(int)\n",
    "        udf = udf[(udf.Rank < 81)]\n",
    "        udf.sort_values(by=['Date', 'Rank'], inplace=True)\n",
    " \n",
    "        #Create points feature\n",
    "        udf['Points'] = udf.Rank.map(points_dict)\n",
    "        udf.Points.fillna(0, inplace=True)\n",
    "    \n",
    "        #Create year feature\n",
    "        udf['Year'] = udf.Date.dt.year\n",
    "    \n",
    "    return udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_from_scraped_web_data():\n",
    "    scraped_df = pd.read_excel('race_dfs_output.xlsx')\n",
    "    \n",
    "    #change name errors\n",
    "    name_dict = {'Sam HILL' : 'Samuel HILL', 'Mick HANNAH' : 'Michael HANNAH'}\n",
    "    venue_dict = {'Fort-William' : 'Fortwilliam', 'Les-Gets' : 'Lesgets', 'Les-Deux-Alpes' : 'Lesdeuxalpes'}\n",
    "    scraped_df.Name.replace(name_dict, inplace=True)\n",
    "    scraped_df.Venue.replace(venue_dict, inplace=True)\n",
    "    scraped_df['Date'] = pd.to_datetime(scraped_df['Date'], format='%Y%m%d')\n",
    "    \n",
    "    #Create points feature\n",
    "    scraped_df['Points'] = scraped_df.Rank.map(points_dict)\n",
    "    scraped_df.Points.fillna(0, inplace=True)\n",
    "    scraped_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    scraped_df = scraped_df[(scraped_df.Rank < 81)]\n",
    "\n",
    "\n",
    "    scraped_df.sort_values(by=['Date', 'Rank'], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    return scraped_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(cfdf):\n",
    "    #Create Moving Average over last 3 races\n",
    "    cfdf['MA3 Pos'] = cfdf.groupby('Name')['Rank'].transform(lambda x: x.rolling(3, 1).mean().shift())\n",
    "\n",
    "    #Create last race position feature\n",
    "    cfdf['Last RP'] = cfdf.groupby('Name')['Rank'].transform(lambda x: x.rolling(1, 1).mean().shift())\n",
    "\n",
    "    #Best position in the last 5 races\n",
    "    cfdf['Best pos'] = cfdf.groupby('Name')['Rank'].transform(lambda x: x.rolling(5, 1).min().shift())\n",
    "\n",
    "    #Average position current season\n",
    "    cfdf['AP this year'] = cfdf.groupby(['Name', 'Year'])['Rank'].transform(lambda x: x.rolling(10, 1).mean().shift())\n",
    "\n",
    "    #Number of races rider has participated in current season\n",
    "    #cfdf['Races CS'] = cfdf.groupby(['Name', 'Year'])['Rank'].transform(lambda x: x.rolling(10, 1).count().shift())\n",
    "    #cfdf['Races CS'].fillna(0, inplace=True)\n",
    "    \n",
    "    return cfdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpreviouswin(compdate, compyear, name, df):    \n",
    "    avgpos_pyear = df[(df.Name == name) & (df.Year == compyear-1)].Rank.mean()\n",
    "    \n",
    "    return pd.Series({'AP last season' : avgpos_pyear})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fantasy_model(dfinp):\n",
    "    #preprocessing of dataframe\n",
    "    \n",
    "    #train and test set to evaluate performance of model before training model on all data and using it to predict\n",
    "    #future competitions\n",
    "    #df_test_snowshoe = dfinp[(dfinp['Venue'] == 'Snowshoe') & (dfinp['Date'] == '2019-09-06')].copy()\n",
    "    #df_train_wo_snowshoe = dfinp[(dfinp['Venue'] != 'Snowshoe') & (dfinp['Date'] != '2019-09-06') & (dfinp.Rank < 81)].copy()\n",
    "    \n",
    "    \n",
    "    #create df to train model on all data before using it to predict upcoming competitions, excluding upcoming competition\n",
    "    df_train = dfinp[(dfinp['Venue'] != ven_pred) & (dfinp['Date'] != date_pred) & (dfinp.Rank < 81)].copy()\n",
    "    #df_pred is the dataframe containing the venue to be predicted\n",
    "    df_pred = dfinp[(dfinp['Venue'] == ven_pred) & (dfinp['Date'] == pd.to_datetime(date_pred, format='%Y%m%d'))].copy()\n",
    "\n",
    "\n",
    "    \n",
    "    y = df_train.Points\n",
    "    df_train.drop('Points', axis=1, inplace=True)\n",
    "    df_pred.drop('Points', axis=1, inplace=True)\n",
    "    #df_test_snowshoe.drop('Points', axis=1, inplace=True)\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numerical_cols = ['Age', 'Year', 'MA3 Pos', 'Last RP', 'Best pos', 'AP this year', 'AP last season']\n",
    "    categorical_cols = ['Name', 'Venue']\n",
    "    \n",
    "\n",
    "    #Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "     ])\n",
    "    \n",
    "    \n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical_cols + numerical_cols\n",
    "    X_train = df_train[my_cols].copy()\n",
    "    X_test = df_pred[my_cols].copy()\n",
    "    #X_test = df_test_snowshoe[my_cols].copy()\n",
    "    \n",
    "    \n",
    "    model = XGBRegressor(n_estimators=600, learning_rate=0.005, n_jobs=4, max_depth=5, objective=\"reg:squarederror\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "\n",
    "    scores = cross_val_score(my_pipeline, X_train, y,\n",
    "                              cv=10,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    print('Neg MAE:', scores)\n",
    "    print(\"NEG MAE mean:\", scores.mean())\n",
    "    print('Standard deviation:', scores.std())\n",
    "    \n",
    "    # Preprocessing of training data, fit model \n",
    "    my_pipeline.fit(X_train, y)\n",
    "    \n",
    "    #Predict points distribution for the race event\n",
    "    test_pred = my_pipeline.predict(X_test)\n",
    "    \n",
    "    return pd.Series(test_pred, df_pred.Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg MAE: [-21.53495574 -18.65106927 -19.88200309 -18.3724795  -19.07697826\n",
      " -18.13124296 -18.33080267 -19.10896065 -20.63797578 -19.86113162]\n",
      "NEG MAE mean: -19.358759954062258\n",
      "Standard deviation: 1.0524852454882159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Amaury PIERRON       107.556709\n",
       "Loic BRUNI           112.596764\n",
       "Troy BROSNAN         102.243080\n",
       "Danny HART            99.010574\n",
       "Loris VERGIER         74.247749\n",
       "                        ...    \n",
       "Kaos SEAGRAVE         12.911288\n",
       "Francisco PARDAL      13.845120\n",
       "Noel NIEDERBERGER     19.722347\n",
       "Gaëtan RUFFIN         14.380709\n",
       "Rupert CHAPMAN        14.586740\n",
       "Length: 87, dtype: float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def race_prediction_men():\n",
    "    #enter names of result folders\n",
    "    path1 = 'Results_UCI_M'\n",
    "    rdf1 = create_results_from_UCI_df(path1)\n",
    "    \n",
    "    scraped_df = create_results_from_scraped_web_data()\n",
    "\n",
    "    result_df_M = scraped_df.append(rdf1, sort=True)\n",
    "        \n",
    "\n",
    "    comp_df_m = create_prediction_df()[0]\n",
    "    \n",
    "    result_df_M = result_df_M.append(comp_df_m, sort=True)\n",
    "\n",
    "    \n",
    "    #create dataframe with features\n",
    "    mdf = create_features(result_df_M)\n",
    "\n",
    "    #create feature with average number points per race for the previous season\n",
    "    mdf[['AP last season']] = mdf.apply(lambda row: findpreviouswin(row.Date, row.Year, row.Name, mdf), axis=1)\n",
    "\n",
    "    mdf.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    #Create correlation plot over the dataframe with numerical features\n",
    "    #f, ax = plt.subplots(figsize=(10, 8))\n",
    "    #corr = mdf.corr()\n",
    "    #sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "    #        square=True, ax=ax)\n",
    "    \n",
    "    return fantasy_model(mdf)\n",
    "race_prediction_men()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_prediction_women():\n",
    "    #enter names of result folders\n",
    "    path1 = 'Results_UCI_W'\n",
    "    rdf1 = create_results_from_UCI_df(path1)\n",
    "    #path2 = 'Results_Web_M'\n",
    "    #rdf2 = create_results_from_web_df(path2)\n",
    "    #result_df_M = rdf2.append(rdf1, sort=True)\n",
    "\n",
    "    \n",
    "    comp_df_w = create_prediction_df()[1]\n",
    "\n",
    "    result_df_W = rdf1.append(comp_df_w, sort=True)\n",
    "\n",
    "\n",
    "\n",
    "    #create dataframe with features\n",
    "    wdf = create_features(result_df_W)\n",
    "\n",
    "    #create feature with average number points per race for the previous season\n",
    "    wdf[['AP last season']] = wdf.apply(lambda row: findpreviouswin(row.Date, row.Year, row.Name, wdf), axis=1)\n",
    "\n",
    "    \n",
    "    return fantasy_model(wdf)\n",
    "#race_prediction_women()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rider_selection(gender):\n",
    "    rider_price_df = pd.read_csv('riderprices2020.csv', sep=';')\n",
    "    \n",
    "    \n",
    "    if gender == 'M':\n",
    "        predictions = race_prediction_men()\n",
    "    else:\n",
    "        predictions = race_prediction_women()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    pri_df = pd.DataFrame(predictions).reset_index()\n",
    "    pri_df = pri_df.rename(columns={0: \"Points\"})\n",
    "\n",
    "    pri_df = pri_df.merge(rider_price_df, left_on='Name', right_on='Name', how='left')\n",
    "    pri_df['Pts./k$'] = pri_df.Points / pri_df.Price*1000\n",
    "    #print(pri_df.head(50))\n",
    "    \n",
    "    if gender == 'M':\n",
    "        pri_df = pri_df.groupby('Price').nth(list(range(4))).reset_index()\n",
    "    else:\n",
    "        pri_df = pri_df.groupby('Price').nth(list(range(2))).reset_index()\n",
    "    \n",
    "    \n",
    "    return pri_df[(pri_df['Pts./k$'] > 0.1)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rider_combinations():\n",
    "    import itertools    \n",
    "    from itertools import combinations\n",
    "    \n",
    "    #dataframe with riders in the men category\n",
    "    ridercm_df = rider_selection('M')\n",
    "    \n",
    "    #dataframe with riders in the women category\n",
    "    ridercw_df = rider_selection('W')\n",
    "    #Create all possible combinations of riders\n",
    "    #mask for non participating riders\n",
    "    #nonpart = (riderc_df.Name != \"Martin MAES\")\n",
    "    #rcomb_df = pd.DataFrame.from_records(list(itertools.combinations(riderc_df[nonpart].Name, 4)), columns=['R1', 'R2', 'R3', 'R4'])\n",
    "    \n",
    "    \n",
    "    #Create two separate dataframes for men and women. \n",
    "    #Create combinations of 4 male riders and combinations of 2 female riders.\n",
    "    \n",
    "    rcombm_df = pd.DataFrame.from_records(list(itertools.combinations(ridercm_df.Name, 4)), columns=['MR1', 'MR2', 'MR3', 'MR4'])\n",
    "\n",
    "    #Dictionaries of rider & price/points\n",
    "    rpdict = dict(zip(ridercm_df.Name,ridercm_df.Price))\n",
    "    rptdict = dict(zip(ridercm_df.Name,ridercm_df.Points))\n",
    "\n",
    "    rcombm_df['CPriceM'] = rcombm_df.MR1.map(rpdict) + rcombm_df.MR2.map(rpdict) + rcombm_df.MR3.map(rpdict) + rcombm_df.MR4.map(rpdict)\n",
    "    rcombm_df['CPointsM'] = rcombm_df.MR1.map(rptdict) + rcombm_df.MR2.map(rptdict) + rcombm_df.MR3.map(rptdict) + rcombm_df.MR4.map(rptdict)\n",
    "    rcombm_df['Comb. Pts/k$'] = rcombm_df.CPointsM / rcombm_df.CPriceM * 1000\n",
    "\n",
    "    rcombm_df.sort_values(by=['CPointsM'], ascending = False, inplace=True)\n",
    "    rcombm_df['RidersM'] = list(zip(rcombm_df.MR1, rcombm_df.MR2, rcombm_df.MR3, rcombm_df.MR4))\n",
    "\n",
    "    #rcombm_df.drop(rcombm_df[rcombm_df.CPriceM > 50000].index, inplace=True)\n",
    "\n",
    "    rcombm_df = rcombm_df[(rcombm_df.CPriceM < 1500000) & (rcombm_df.CPriceM > 340000)].copy()\n",
    "    \n",
    "    #Creation of dataframes for female riders\n",
    "    rcombw_df = pd.DataFrame.from_records(list(itertools.combinations(ridercw_df.Name, 2)), columns=['WR1', 'WR2'])\n",
    "    \n",
    "    rpwdict = dict(zip(ridercw_df.Name,ridercw_df.Price))\n",
    "    rptwdict = dict(zip(ridercw_df.Name,ridercw_df.Points))\n",
    "    \n",
    "    rcombw_df['CPriceW'] = rcombw_df.WR1.map(rpwdict) + rcombw_df.WR2.map(rpwdict) \n",
    "    rcombw_df['CPointsW'] = rcombw_df.WR1.map(rptwdict) + rcombw_df.WR2.map(rptwdict) \n",
    "    rcombw_df['Comb. Pts/k$ W'] = rcombw_df.CPointsW / rcombw_df.CPriceW * 1000\n",
    "\n",
    "    rcombw_df.sort_values(by=['CPointsW'], ascending = False, inplace=True)\n",
    "    rcombw_df['RidersW'] = list(zip(rcombw_df.WR1, rcombw_df.WR2))\n",
    "\n",
    "    #find best combinations of both men and women\n",
    "    combinate_df = pd.DataFrame.from_records(list(itertools.product(rcombw_df.RidersW, rcombm_df.RidersM)), columns=['RidersW', 'RidersM'])\n",
    "    \n",
    "    \n",
    "    combinate_df = combinate_df.merge(rcombw_df, left_on='RidersW', right_on='RidersW')\n",
    "    combinate_df = combinate_df.merge(rcombm_df, left_on='RidersM', right_on='RidersM')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    combinate_df['Combined Price'] = combinate_df.CPriceW + combinate_df.CPriceM\n",
    "    combinate_df['Combined Points'] = combinate_df.CPointsW + combinate_df.CPointsM\n",
    "\n",
    "    combinate_df.drop(['MR1', 'MR2', 'MR3', 'MR4', 'WR1', 'WR2', 'CPriceW', 'CPriceM', 'CPointsW', 'CPointsM'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    combinate_df.sort_values(by=['Combined Points'], ascending = False, inplace=True)\n",
    "    \n",
    "    return combinate_df[(combinate_df['Combined Price'] < 1500001)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg MAE: [-20.20925308 -19.23591384 -18.66822861 -18.9025378  -20.46353049]\n",
      "NEG MAE mean: -19.495892762504287\n",
      "Standard deviation: 0.7141278316338439\n",
      "Neg MAE: [-21.24704232 -20.17804755 -16.781443   -18.29845971 -25.28411114]\n",
      "NEG MAE mean: -20.357820743870086\n",
      "Standard deviation: 2.9025098128010756\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RidersW</th>\n",
       "      <th>RidersM</th>\n",
       "      <th>Comb. Pts/k$ W</th>\n",
       "      <th>Comb. Pts/k$</th>\n",
       "      <th>Combined Price</th>\n",
       "      <th>Combined Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1998618</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Taylor VERNON, Brendan FAIRCLOUGH, Aaron GWIN...</td>\n",
       "      <td>0.459818</td>\n",
       "      <td>0.275381</td>\n",
       "      <td>1500000</td>\n",
       "      <td>509.900717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001018</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Joe BREEDEN, Brendan FAIRCLOUGH, Aaron GWIN, ...</td>\n",
       "      <td>0.459818</td>\n",
       "      <td>0.275365</td>\n",
       "      <td>1500000</td>\n",
       "      <td>509.885302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2257218</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Baptiste PIERRON, David TRUMMER, Charlie HARR...</td>\n",
       "      <td>0.459818</td>\n",
       "      <td>0.272929</td>\n",
       "      <td>1500000</td>\n",
       "      <td>507.510098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2276418</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Joshua BARTH, Brendan FAIRCLOUGH, Aaron GWIN,...</td>\n",
       "      <td>0.459818</td>\n",
       "      <td>0.284427</td>\n",
       "      <td>1460000</td>\n",
       "      <td>507.343550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2319618</td>\n",
       "      <td>(Morgane CHARRE, Myriam NICOLE)</td>\n",
       "      <td>(Brendan FAIRCLOUGH, David TRUMMER, Charlie HA...</td>\n",
       "      <td>0.459818</td>\n",
       "      <td>0.287011</td>\n",
       "      <td>1450000</td>\n",
       "      <td>506.889523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74867389</td>\n",
       "      <td>(Melanie CHAPPAZ, Vali HÖLL)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...</td>\n",
       "      <td>0.284697</td>\n",
       "      <td>0.152088</td>\n",
       "      <td>750000</td>\n",
       "      <td>163.794289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74867388</td>\n",
       "      <td>(Cecile RAVANEL, Vali HÖLL)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...</td>\n",
       "      <td>0.170818</td>\n",
       "      <td>0.152088</td>\n",
       "      <td>1000000</td>\n",
       "      <td>163.794289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74867387</td>\n",
       "      <td>(Janine HUBSCHER, Mille JOHNSET)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...</td>\n",
       "      <td>0.667258</td>\n",
       "      <td>0.152088</td>\n",
       "      <td>535000</td>\n",
       "      <td>163.794289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74867386</td>\n",
       "      <td>(Melanie CHAPPAZ, Cecile RAVANEL)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...</td>\n",
       "      <td>0.305032</td>\n",
       "      <td>0.152088</td>\n",
       "      <td>725000</td>\n",
       "      <td>163.794289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74867399</td>\n",
       "      <td>(Janine HUBSCHER, Vali HÖLL)</td>\n",
       "      <td>(Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...</td>\n",
       "      <td>0.318690</td>\n",
       "      <td>0.152088</td>\n",
       "      <td>710000</td>\n",
       "      <td>163.794289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57765567 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RidersW  \\\n",
       "1998618     (Morgane CHARRE, Myriam NICOLE)   \n",
       "2001018     (Morgane CHARRE, Myriam NICOLE)   \n",
       "2257218     (Morgane CHARRE, Myriam NICOLE)   \n",
       "2276418     (Morgane CHARRE, Myriam NICOLE)   \n",
       "2319618     (Morgane CHARRE, Myriam NICOLE)   \n",
       "...                                     ...   \n",
       "74867389       (Melanie CHAPPAZ, Vali HÖLL)   \n",
       "74867388        (Cecile RAVANEL, Vali HÖLL)   \n",
       "74867387   (Janine HUBSCHER, Mille JOHNSET)   \n",
       "74867386  (Melanie CHAPPAZ, Cecile RAVANEL)   \n",
       "74867399       (Janine HUBSCHER, Vali HÖLL)   \n",
       "\n",
       "                                                    RidersM  Comb. Pts/k$ W  \\\n",
       "1998618   (Taylor VERNON, Brendan FAIRCLOUGH, Aaron GWIN...        0.459818   \n",
       "2001018   (Joe BREEDEN, Brendan FAIRCLOUGH, Aaron GWIN, ...        0.459818   \n",
       "2257218   (Baptiste PIERRON, David TRUMMER, Charlie HARR...        0.459818   \n",
       "2276418   (Joshua BARTH, Brendan FAIRCLOUGH, Aaron GWIN,...        0.459818   \n",
       "2319618   (Brendan FAIRCLOUGH, David TRUMMER, Charlie HA...        0.459818   \n",
       "...                                                     ...             ...   \n",
       "74867389  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...        0.284697   \n",
       "74867388  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...        0.170818   \n",
       "74867387  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...        0.667258   \n",
       "74867386  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...        0.305032   \n",
       "74867399  (Thibault RUFFIN, Alexandre FAYOLLE, Lucas CRU...        0.318690   \n",
       "\n",
       "          Comb. Pts/k$  Combined Price  Combined Points  \n",
       "1998618       0.275381         1500000       509.900717  \n",
       "2001018       0.275365         1500000       509.885302  \n",
       "2257218       0.272929         1500000       507.510098  \n",
       "2276418       0.284427         1460000       507.343550  \n",
       "2319618       0.287011         1450000       506.889523  \n",
       "...                ...             ...              ...  \n",
       "74867389      0.152088          750000       163.794289  \n",
       "74867388      0.152088         1000000       163.794289  \n",
       "74867387      0.152088          535000       163.794289  \n",
       "74867386      0.152088          725000       163.794289  \n",
       "74867399      0.152088          710000       163.794289  \n",
       "\n",
       "[57765567 rows x 6 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_rider_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
